# Загрузка необходимых библиотек
import numpy as np
import matplotlib.pyplot as plt


# обучающая выборка с тремя признаками (третий - константа +1)
data_x = [[3.0, 1.3], [3.4, 1.6], [3.4, 0.4], [3.7, 0.2], [3.5, 0.2], [3.4, 0.2], [3.4, 0.4], [3.9, 0.4], [3.4, 0.3],
          [3.2, 0.2], [2.8, 1.3], [3.5, 0.3], [2.4, 1.0], [3.0, 0.1], [3.6, 0.2], [3.2, 0.2], [2.9, 0.2], [2.9, 1.3],
          [2.3, 1.3], [3.8, 0.2], [3.2, 1.5], [2.3, 1.0], [3.0, 1.7], [3.3, 0.2], [3.4, 0.2], [3.8, 0.3], [2.0, 1.0],
          [3.1, 0.2], [2.5, 1.3], [2.4, 1.1], [3.2, 0.2], [2.2, 1.0], [3.1, 1.4], [3.0, 0.2], [3.0, 0.2], [3.4, 0.2],
          [3.7, 0.2], [2.8, 1.2], [2.9, 1.4], [4.0, 0.2], [3.2, 1.4], [3.2, 0.2], [2.9, 1.3], [2.9, 1.3], [3.5, 0.2],
          [3.3, 1.6], [2.9, 1.3], [2.7, 1.0], [2.9, 1.3], [3.4, 0.2], [3.2, 0.2], [4.1, 0.1], [3.5, 0.6], [2.7, 1.4],
          [2.3, 0.3], [2.9, 1.5], [3.1, 1.5], [3.5, 0.2], [2.7, 1.6], [3.3, 0.5], [3.0, 1.4], [3.6, 0.2], [3.0, 1.2],
          [2.8, 1.3], [2.5, 1.1], [3.0, 1.5], [3.1, 0.2], [2.6, 1.0], [2.7, 1.2], [2.2, 1.5], [3.7, 0.4], [3.4, 0.2],
          [3.5, 0.3], [3.6, 0.1], [2.5, 1.5], [2.6, 1.2], [2.8, 1.3], [3.1, 0.1], [2.4, 1.0], [3.1, 1.5], [2.3, 1.3],
          [2.8, 1.5], [3.0, 0.3], [3.0, 0.2], [2.5, 1.1], [3.0, 1.5], [3.2, 1.8], [3.9, 0.4], [2.8, 1.4], [4.2, 0.2],
          [3.4, 0.2], [2.7, 1.3], [3.8, 0.3], [3.0, 1.4], [2.6, 1.2], [4.4, 0.4], [3.8, 0.4], [3.1, 0.2], [3.0, 0.1],
          [3.0, 1.5]]
data_y = [1, 1, -1, -1, -1, -1, -1, -1, -1, -1, 1, -1, 1, -1, -1, -1, -1, 1, 1, -1, 1, 1, 1, -1, -1, -1, 1, -1, 1, 1,
          -1, 1, 1, -1, -1, -1, -1, 1, 1, -1, 1, -1, 1, 1, -1, 1, 1, 1, 1, -1, -1, -1, -1, 1, -1, 1, 1, -1, 1, -1, 1,
          -1, 1, 1, 1, 1, -1, 1, 1, 1, -1, -1, -1, -1, 1, 1, 1, -1, 1, 1, 1, 1, -1, -1, 1, 1, 1, -1, 1, -1, -1, 1, -1,
          1, 1, -1, -1, -1, -1, 1]

x_train = np.array(data_x)            # обучающая выборка по x
y_train = np.array(data_y)            # обучающая выборка по y

n_dot=len(y_train)                    # общее число точек
n_dot_class1 = 0                      # число точек, принадлежащих классу 1
n_dot_class2 = 0                      # число точек, принадлежащих классу 2
# определение количества точек, принадлежащих к каждому классу
for i in range(n_dot):
    if y_train[i] == 1:
        n_dot_class1 +=1
    else:
        n_dot_class2 +=1

mean_class1_x1, mean_class1_x2 = np.mean(x_train[y_train == 1], axis=0) # МО для класса 1
mean_class2_x1, mean_class2_x2 = np.mean(x_train[y_train == -1], axis=0) # МО для класса 2

disp_class1_x1, disp_class1_x2 = np.var(x_train[y_train == 1], axis=0) # Дисперсия для класса 1
disp_class2_x1, disp_class2_x2 = np.var(x_train[y_train == -1], axis=0) # Дисперсия для класса 2

# Определение принадлежности точек обучающей выборки к классу 1 или классу 2
a_class2 = lambda x: -(x[0] - mean_class2_x1) ** 2 / (2 * disp_class2_x1) - (x[1] - mean_class2_x2) ** 2 / (2 * disp_class2_x2)
a_class1 = lambda x: -(x[0] - mean_class1_x1) ** 2 / (2 * disp_class1_x1) - (x[1] - mean_class1_x2) ** 2 / (2 * disp_class1_x2)
n_err = 0                           # количество ошибок классификации
for i in range(n_dot):
    dot_curr_x = x_train[i]      # координата х текущей точки
    dot_curr_y = y_train[i]      # координата y текущей точки
    aa = a_class1(dot_curr_x)
    aaa = a_class2(dot_curr_x)
    if a_class1(dot_curr_x) >= a_class2(dot_curr_x):
        class_temp = 1        # классификация к классу 1
    else:
        class_temp = -1        # классификация к классу 2
    if (dot_curr_y - class_temp) != 0:
        n_err += 1
n_err_perc = (n_err/n_dot)*100     # количество ошибок классификации в процентах
print('===========================Наивный байесовский классификатор ')

print("Общее количество точек n = %d" % (n_dot))
print("Количество точек, относящихся к классу 1 = %d" % (n_dot_class1))
print("Количество точек, относящихся к классу 2 = %d" % (n_dot_class1))

print("МО точек, относящихся к классу 1 : [%f, %f]" % (mean_class1_x1, mean_class1_x2))
print("Дисперсия точек, относящихся к классу 1 : [%f, %f]" % (disp_class1_x1, disp_class1_x2))
print("МО точек, относящихся к классу 2 : [%f, %f]" % (mean_class2_x1, mean_class2_x2))
print("Дисперсия точек, относящихся к классу 2 : [%f, %f]" % (disp_class2_x1, disp_class2_x2))
print("Число неверных классификаций на обучающей выборке n_err = %d" % (n_err))
print("Процент неверных классификаций на обучающей выборке n_err_perc = %f" % (n_err_perc))

#===Пример работы наивного байессовского классификатора
print("====================================================")
print("Пример работы наивного байессовского классификатора")
x_example1 = [1, 1]
print("Координаты тестовой точки x_example1 = [%f, %f]" % (x_example1[0], x_example1[1]))
y_res = np.argmax([a_class1(x_example1), a_class2(x_example1)])
print('Номер класса (0 - Класс 1, 1 - Класс 2): ', y_res)

x_example2 = [1, 0.25]
print("Координаты тестовой точки x_example2 = [%f, %f]" % (x_example2[0], x_example2[1]))
y_res = np.argmax([a_class1(x_example2), a_class2(x_example2)])
print('Номер класса (0 - Класс 1, 1 - Класс 2): ', y_res)

x_0 = x_train[y_train == 1]                 # формирование точек для 1-го
x_1 = x_train[y_train == -1]                # и 2-го классов
max_x1_int = round(max(x_train[:, 0])) + 2 # максимальное округленное целое значение х1 в выборке (с запасом)
max_x1_float = round(max(x_train[:, 0]),1) + 0.1 # максимальное овещественное целое значение х1 в выборке (с запасом)
max_x2_float = round(max(x_train[:, 1]),1) + 0.1 # максимальное овещественное целое значение х2 в выборке (с запасом)
#===отрисовка графика
#plt.scatter(x_0[:, 0], x_0[:, 1], color='red')
plt.scatter(x_0[:, 0], x_0[:, 1], marker = '^', color='red', label = 'Класс 1')
plt.scatter(x_1[:, 0], x_1[:, 1], color='blue', label = 'Класс 2')
plt.xlim([0, max_x1_float])
plt.ylim([0, max_x2_float])
plt.ylabel("x2")
plt.xlabel("x1")
plt.title("Обучающая выборка по классам")
plt.legend()
plt.grid(True)
plt.show()







print('МО: ', mw1, ml1, mw_1, ml_1)
#print('Дисперсии:', sw1, sl1, sw_1, sl_1)



